
# This section maps ingest process names to the DAGs that initiate ingest for that process
[ingest_map]
MICROSCOPY.IMS.ALL = ingest_vanderbilt
MOCK.MICROSCOPY.IMS.ALL = mock_ingest_vanderbilt
MOCK.RNASEQ.10X = mock_ingest_rnaseq_10x
SCAN.AND.BEGIN.PROCESSING = scan_and_begin_processing

[core]
timezone = US/Eastern

[connections]

# Globus App ID and secret, to be set at config time
APP_CLIENT_ID = ''
APP_CLIENT_SECRET = ''

# Base path for dataset files, as seen by Airflow.  This will usually correspond to
# GLOBUS_ENDPOINT_BASE_PATH in ingest-api .  When ingest-pipeline runs in a docker 
# container, this is the path to which the staging area is mounted.  When the full path
# to a dataset is passed to ingest-pipeline, this is expected to be the first part
# of that path.
DOCKER_MOUNT_PATH = '/usr/local/airflow/lz/'

# Path to src/ingest-pipeline directory as seen by airflow
SRC_PATH = '/usr/src/app/src'

# Path to temporary storage for workflow as seen by airflow
WORKFLOW_SCRATCH = '/hive/hubmap-dev/scratch'

# Group to which output directories are set, typically shared with Globus
OUTPUT_GROUP_NAME = 'dataaccessgroup'

# Optional template for use in customizing queue names, for better Celery sharing
#QUEUE_NAME_TEMPLATE = '{}-test'

[globus]
app_client_id =
app_client_secret =
oauth_callback_route = /login
# If you are running localhost, set this to http. Otherwise, set this to https.
scheme = https
# Should be a CSV of group names (not quote wrapped) that you would like to give access to
# EX: group_1, group_2
hubmap_groups = hubmap-data-admin, hubmap-data-curator

[webserver]
auth_backend = globus_auth.globus_auth
